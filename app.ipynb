{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNt0DnSyQ3O9j4jcePC6QF0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%pip install pyngrok"],"metadata":{"id":"dCVXGLtI9Drd","executionInfo":{"status":"ok","timestamp":1771412579082,"user_tz":-330,"elapsed":9395,"user":{"displayName":"Naaz Mulla","userId":"17508237092567102754"}},"outputId":"7d6aae4a-26b3-47bb-8f75-926f5ebc4934","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyngrok\n","  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n","Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.5.0\n"]}]},{"cell_type":"code","source":["# ----------------------------------------------------------------------\n","# 1. SETUP AND IMPORTS\n","# ----------------------------------------------------------------------\n","# Load Dataset - This line MUST be present for Drive access in Colab!\n","from google.colab import drive\n","import joblib\n","import pandas as pd\n","from flask import Flask, request, jsonify\n","from pyngrok import ngrok, __version__ as ngrok_version\n","import os\n","import sys\n","import threading\n","import time\n","import requests # Added for the test script\n","import json # Added for the test script\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# --- SETUP: Load Model and Preprocessors on Startup ---\n","try:\n","    # âš ï¸ NOTE: Use the absolute path where your files are stored in Google Drive\n","    base_path = '/content/drive/MyDrive/Deep CSAT Project'\n","\n","    model = joblib.load(os.path.join(base_path, 'model.joblib'))\n","    scaler = joblib.load(os.path.join(base_path, 'scaler.joblib'))\n","    feature_names = joblib.load(os.path.join(base_path, 'feature_names.joblib'))\n","    print(\"Models and Scalers loaded successfully from Google Drive.\")\n","\n","except Exception as e:\n","    # Exit gracefully if critical files are missing.\n","    print(f\"ERROR: Failed to load models from Drive: {e}\", file=sys.stderr)\n","    sys.exit(1)\n","\n","# --- FLASK APP DEFINITION ---\n","app = Flask(__name__)\n","\n","# ----------------------------------------------------------------------\n","# 2. API ENDPOINT\n","# ----------------------------------------------------------------------\n","\n","# --- Root Endpoint for Health Check and Instructions ---\n","@app.route('/', methods=['GET'])\n","def home():\n","    \"\"\"Simple health check and API instructions.\"\"\"\n","    return jsonify({\n","        'status': 'API Running',\n","        'message': 'Send a POST request to /predict with JSON data for CSAT prediction.',\n","        'ngrok_version': ngrok_version\n","    })\n","\n","\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    \"\"\"\n","    Receives raw customer features via POST request, preprocesses them,\n","    and returns a CSAT prediction.\n","    \"\"\"\n","    try:\n","        # 1. Get raw JSON data from the request\n","        raw_data = request.get_json()\n","\n","        # Check if raw_data is missing or empty\n","        if not raw_data:\n","            return jsonify({'error': 'No input data provided.'}), 400\n","\n","        # 2. Convert to DataFrame (API handles one customer at a time)\n","        input_df = pd.DataFrame([raw_data])\n","\n","        # --- 3. PREPROCESSING LOGIC ---\n","\n","        # a. Align columns: Create a DataFrame with all 92 expected columns.\n","        X_predict = input_df.reindex(columns=feature_names, fill_value=0)\n","\n","        # b. Scale the data using the saved scaler\n","        X_scaled = scaler.transform(X_predict.values)\n","\n","        # --- 4. PREDICTION ---\n","        prediction = model.predict(X_scaled)\n","\n","        # 5. Format Output\n","        prediction_value = int(prediction[0])\n","        prediction_label = \"High CSAT (1)\" if prediction_value == 1 else \"Low CSAT (0)\"\n","\n","        return jsonify({\n","            'prediction_label': prediction_label,\n","            'prediction_value': prediction_value,\n","            'model_used': 'XGBoost (Tuned)'\n","        })\n","\n","    except Exception as e:\n","        # Return a clean error message if something fails\n","        print(f\"Prediction error: {e}\", file=sys.stderr)\n","        return jsonify({'error': f'Prediction failed: {str(e)}'}), 400\n","\n","# ----------------------------------------------------------------------\n","# 3. NGROK SETUP AND SERVER RUN (Most Stable)\n","# ----------------------------------------------------------------------\n","def run_tunnel():\n","    \"\"\"Starts the ngrok tunnel in a separate thread.\"\"\"\n","\n","    colab_port = 5000\n","\n","    # 1. Kill any existing ngrok process and tunnel connections\n","    try:\n","        ngrok.kill()\n","    except Exception:\n","        pass\n","\n","    # --- STEP 1.5: EXPLICITLY SET AUTH TOKEN ---\n","    # âš ï¸ MANDATORY: PASTE YOUR NGROK AUTH TOKEN HERE\n","    NGROK_AUTH_TOKEN = \"35pir11lSH5XI1eaAdtDWDuoP9V_7SYe3ZAu9kz6VdA21VoA\"\n","    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n","\n","    print(f\"\\nStarting ngrok tunnel on port {colab_port}...\")\n","\n","    # 2. Start the ngrok tunnel manually\n","    try:\n","        public_url = ngrok.connect(colab_port).public_url\n","        print(f\"ðŸŽ‰ * Ngrok Tunnel is LIVE! Public URL: {public_url} * ðŸŽ‰\")\n","        print(\"To stop the server, interrupt this cell (Runtime -> Interrupt execution).\")\n","\n","        # --- Run the client test after confirming the public URL is available ---\n","        # The test is wrapped in a thread to run concurrently with the Flask server\n","        test_thread = threading.Thread(target=run_api_test, args=(public_url,))\n","        test_thread.start()\n","\n","    except Exception as e:\n","        print(f\"âŒ NGROK FAILED: Please check your token and ensure it is correct. Error: {e}\", file=sys.stderr)\n","        return\n","\n","    # 3. Start the Flask app\n","    app.run(port=colab_port, host=\"0.0.0.0\", debug=False, use_reloader=False)\n","\n","\n","# ----------------------------------------------------------------------\n","# 4. API CLIENT TEST SCRIPT (Updated with user's new values)\n","# ----------------------------------------------------------------------\n","def run_api_test(ngrok_url):\n","    \"\"\"\n","    Tests the deployed Flask API with a high-risk payload.\n","    This runs in a separate thread after the server is confirmed up.\n","    \"\"\"\n","    # Delay to ensure the server is fully bound before sending the request\n","    time.sleep(5)\n","\n","    API_URL = f\"{ngrok_url}/predict\"\n","\n","    # Define a high-risk customer payload (Long response time, negative sentiment)\n","    HIGH_RISK_PAYLOAD = {\n","        # CRITICAL PREDICTIVE FEATURES (Updated with user's new data)\n","        \"Response_Time_Minutes\": 5.33,\n","\n","        \"Sentiment_Score\": -0.91,     # Very negative\n","        \"Remark_Word_Count\": 15,      # Verbose complaint\n","\n","        # CATEGORICAL FEATURES\n","        \"channel_name_Phone\": 1,\n","        \"category_Billing\": 1,\n","\n","        # OTHER FEATURES\n","        \"Item_price\": 5000,\n","        \"connected_handling_time\": 427,\n","\n","        # Tenure feature\n","        \"Tenure Bucket_Mid-Level\": 1\n","    }\n","\n","    print(\"\\n--- Sending High-Risk Payload to LIVE API (Client Test) ---\")\n","    print(f\"Target URL: {API_URL}\")\n","    print(f\"Data Sent: {json.dumps(HIGH_RISK_PAYLOAD, indent=2)}\")\n","\n","    try:\n","        response = requests.post(API_URL, json=HIGH_RISK_PAYLOAD)\n","        response.raise_for_status()\n","\n","        prediction_result = response.json()\n","\n","        print(\"\\nâœ… API Prediction Successful:\")\n","        print(json.dumps(prediction_result, indent=4))\n","\n","    except requests.exceptions.RequestException as e:\n","        print(f\"\\nâŒ ERROR: Failed to get prediction from API.\")\n","        print(f\"Details: {e}\")\n","        if 'response' in locals() and hasattr(response, 'text'):\n","            print(f\"API Response Text: {response.text}\")\n","\n","\n","if __name__ == '__main__':\n","    # Start the ngrok tunnel and the Flask app.\n","    # The run_tunnel function will then start the test script in its own thread.\n","    tunnel_thread = threading.Thread(target=run_tunnel)\n","    tunnel_thread.start()\n","\n","    # Wait for the tunnel thread to complete its setup\n","    time.sleep(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I6v8iHJcZYb3","executionInfo":{"status":"ok","timestamp":1771412662439,"user_tz":-330,"elapsed":83350,"user":{"displayName":"Naaz Mulla","userId":"17508237092567102754"}},"outputId":"64e53976-9ed6-48dc-de97-74d4d20c0755"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.12/pickle.py:1760: UserWarning: [11:04:13] WARNING: /__w/xgboost/xgboost/src/collective/../data/../common/error_msg.h:83: If you are loading a serialized model (like pickle in Python, RDS in R) or\n","configuration generated by an older version of XGBoost, please export the model by calling\n","`Booster.save_model` from that version first, then load it back in current version. See:\n","\n","    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n","\n","for more details about differences between saving model and serializing.\n","\n","  setstate(state)\n"]},{"output_type":"stream","name":"stdout","text":["Models and Scalers loaded successfully from Google Drive.\n","\n","Starting ngrok tunnel on port 5000...\n","ðŸŽ‰ * Ngrok Tunnel is LIVE! Public URL: https://fec0-34-132-98-222.ngrok-free.app * ðŸŽ‰\n","To stop the server, interrupt this cell (Runtime -> Interrupt execution).\n"," * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on all addresses (0.0.0.0)\n"," * Running on http://127.0.0.1:5000\n"," * Running on http://172.28.0.12:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"]}]}]}